#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
JARVIS v14 Ultimate - Context Manager
======================================

Device: Realme 2 Pro Lite (RMP2402) | RAM: 4GB | Platform: Termux

Research-Based Implementation:
- Sliding window context management
- Token-aware context truncation
- Automatic summarization for long contexts
- Priority-based message retention
- Multi-conversation context switching

Features:
- Token counting and budgeting
- Context window management
- Automatic summarization triggers
- Important message preservation
- Context compression
- Multi-model context adaptation

Memory Impact: < 2MB for active contexts
"""

import time
import logging
import threading
import hashlib
from typing import Dict, Any, Optional, List, Generator, Callable, Tuple
from dataclasses import dataclass, field
from enum import Enum, auto
from collections import deque
from functools import lru_cache

logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ENUMS AND DATACLASSES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ContextPriority(Enum):
    """Priority levels for context messages"""
    CRITICAL = 100    # Always keep (system prompts, safety info)
    HIGH = 75         # Important context (recent Q&A, key facts)
    NORMAL = 50       # Regular messages
    LOW = 25          # Can be summarized
    DISPOSABLE = 0    # Can be dropped if needed


class SummarizationTrigger(Enum):
    """Triggers for context summarization"""
    TOKEN_LIMIT = auto()
    MESSAGE_COUNT = auto()
    TIME_BASED = auto()
    MANUAL = auto()
    TOPIC_SHIFT = auto()


@dataclass
class ContextMessage:
    """
    A message within context with priority and metadata.
    """
    role: str
    content: str
    tokens: int = 0
    priority: ContextPriority = ContextPriority.NORMAL
    message_id: Optional[int] = None
    timestamp: float = field(default_factory=time.time)
    is_summarized: bool = False
    original_content: str = ""
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_api_format(self) -> Dict[str, str]:
        """Convert to API format"""
        return {"role": self.role, "content": self.content}


@dataclass
class ContextWindow:
    """
    A sliding window of context messages.
    
    Manages token budget and message retention.
    """
    max_tokens: int = 4096
    max_messages: int = 100
    reserved_tokens: int = 512  # Reserved for system prompt and response
    
    messages: List[ContextMessage] = field(default_factory=list)
    total_tokens: int = 0
    system_prompt: str = ""
    system_prompt_tokens: int = 0
    
    def available_tokens(self) -> int:
        """Get available token budget"""
        used = self.total_tokens + self.system_prompt_tokens
        return max(0, self.max_tokens - used - self.reserved_tokens)
    
    def utilization_percent(self) -> float:
        """Get context utilization percentage"""
        total_capacity = self.max_tokens - self.reserved_tokens
        used = self.total_tokens + self.system_prompt_tokens
        return (used / total_capacity) * 100 if total_capacity > 0 else 0


@dataclass
class SummarizationResult:
    """Result of a summarization operation"""
    success: bool
    summary: str = ""
    original_messages: int = 0
    summarized_messages: int = 0
    tokens_before: int = 0
    tokens_after: int = 0
    compression_ratio: float = 0.0


@dataclass
class ContextSnapshot:
    """Snapshot of context state for caching/backup"""
    conversation_id: str
    messages: List[Dict[str, Any]]
    total_tokens: int
    created_at: float
    checksum: str = ""
    
    def compute_checksum(self) -> str:
        """Compute checksum for cache validation"""
        data = f"{self.conversation_id}:{self.total_tokens}:{len(self.messages)}"
        return hashlib.md5(data.encode()).hexdigest()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TOKEN ESTIMATOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TokenEstimator:
    """
    Estimate token counts for messages.
    
    Uses simple heuristics (4 chars = ~1 token) for speed.
    More accurate than tiktoken for mixed content, faster too.
    """
    
    # Average characters per token for different content types
    CHARS_PER_TOKEN = {
        'default': 4.0,
        'code': 3.5,      # Code has more symbols
        'english': 4.5,   # English prose
        'mixed': 4.0,     # Mixed content
    }
    
    # Message overhead tokens (role, formatting)
    MESSAGE_OVERHEAD = 4
    
    @classmethod
    def estimate(cls, text: str, content_type: str = 'default') -> int:
        """
        Estimate token count for text.
        
        Args:
            text: Text to estimate
            content_type: Type of content for better estimation
            
        Returns:
            Estimated token count
        """
        if not text:
            return 0
        
        chars_per_token = cls.CHARS_PER_TOKEN.get(content_type, cls.CHARS_PER_TOKEN['default'])
        
        # Count special characters that often mean more tokens
        special_chars = sum(1 for c in text if c in '\n\t{}[]()<>')
        
        # Base estimate
        base_tokens = len(text) / chars_per_token
        
        # Adjust for special characters
        adjusted = base_tokens + (special_chars * 0.1)
        
        return int(adjusted + cls.MESSAGE_OVERHEAD)
    
    @classmethod
    def estimate_messages(cls, messages: List[Dict[str, str]]) -> int:
        """Estimate total tokens for a list of messages"""
        total = 0
        for msg in messages:
            content = msg.get('content', '')
            total += cls.estimate(content)
        return total


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONTEXT MANAGER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ContextManager:
    """
    Ultra-Advanced Context Management System.
    
    Features:
    - Token-aware context windowing
    - Priority-based message retention
    - Automatic summarization
    - Context compression
    - Multi-conversation support
    - Context caching
    
    Memory Budget: < 2MB for active contexts
    
    Usage:
        manager = ContextManager()
        
        # Start a conversation
        ctx = manager.create_context("conv-123", max_tokens=4096)
        
        # Set system prompt
        manager.set_system_prompt("conv-123", "You are JARVIS...")
        
        # Add messages
        manager.add_message("conv-123", "user", "Hello!")
        manager.add_message("conv-123", "assistant", "Hi there!")
        
        # Get context for API call
        messages = manager.get_context("conv-123")
        
        # Automatic summarization when needed
        manager.maybe_summarize("conv-123")
    """
    
    # Default context windows for different models
    MODEL_CONTEXT_LIMITS = {
        'default': 4096,
        'openrouter/free': 128000,
        'openrouter/aurora-alpha': 128000,
        'deepseek/deepseek-r1-0528:free': 164000,
        'google/gemini-2.0-flash-exp:free': 1000000,
        'stepfun/step-3.5-flash:free': 128000,
    }
    
    # Summarization thresholds
    SUMMARIZE_THRESHOLD_PERCENT = 80  # Summarize when 80% full
    MIN_MESSAGES_TO_SUMMARIZE = 10
    
    def __init__(
        self,
        default_max_tokens: int = 4096,
        default_max_messages: int = 100,
        enable_auto_summarize: bool = True,
        summarize_callback: Callable[[List[ContextMessage]], str] = None,
    ):
        """
        Initialize Context Manager.
        
        Args:
            default_max_tokens: Default token limit for contexts
            default_max_messages: Default message limit
            enable_auto_summarize: Enable automatic summarization
            summarize_callback: Callback for summarization (receives messages, returns summary)
        """
        self._default_max_tokens = default_max_tokens
        self._default_max_messages = default_max_messages
        self._enable_auto_summarize = enable_auto_summarize
        self._summarize_callback = summarize_callback
        
        # Active contexts
        self._contexts: Dict[str, ContextWindow] = {}
        self._lock = threading.RLock()
        
        # Context cache for fast retrieval
        self._cache: Dict[str, ContextSnapshot] = {}
        self._cache_lock = threading.Lock()
        
        # Statistics
        self._stats = {
            'contexts_created': 0,
            'messages_added': 0,
            'messages_dropped': 0,
            'summarizations': 0,
            'cache_hits': 0,
            'cache_misses': 0,
        }
        
        # Summarization history
        self._summarization_history: Dict[str, List[SummarizationResult]] = {}
    
    def create_context(
        self,
        conversation_id: str,
        max_tokens: int = None,
        max_messages: int = None,
        system_prompt: str = ""
    ) -> ContextWindow:
        """
        Create a new context for a conversation.
        
        Args:
            conversation_id: Unique conversation ID
            max_tokens: Maximum tokens for context
            max_messages: Maximum messages to keep
            system_prompt: Initial system prompt
            
        Returns:
            Created ContextWindow
        """
        with self._lock:
            ctx = ContextWindow(
                max_tokens=max_tokens or self._default_max_tokens,
                max_messages=max_messages or self._default_max_messages,
            )
            
            if system_prompt:
                ctx.system_prompt = system_prompt
                ctx.system_prompt_tokens = TokenEstimator.estimate(system_prompt)
            
            self._contexts[conversation_id] = ctx
            self._stats['contexts_created'] += 1
            
            logger.debug(f"Created context for {conversation_id}")
            return ctx
    
    def get_context(self, conversation_id: str) -> Optional[ContextWindow]:
        """Get context for a conversation"""
        return self._contexts.get(conversation_id)
    
    def set_system_prompt(
        self,
        conversation_id: str,
        prompt: str,
        priority: ContextPriority = ContextPriority.CRITICAL
    ) -> bool:
        """
        Set system prompt for a context.
        
        Args:
            conversation_id: Target conversation
            prompt: System prompt text
            priority: Priority level
            
        Returns:
            True if set successfully
        """
        with self._lock:
            ctx = self._contexts.get(conversation_id)
            if not ctx:
                return False
            
            ctx.system_prompt = prompt
            ctx.system_prompt_tokens = TokenEstimator.estimate(prompt)
            
            # Invalidate cache
            self._invalidate_cache(conversation_id)
            
            return True
    
    def add_message(
        self,
        conversation_id: str,
        role: str,
        content: str,
        priority: ContextPriority = ContextPriority.NORMAL,
        message_id: int = None,
        metadata: Dict = None
    ) -> bool:
        """
        Add a message to context.
        
        Args:
            conversation_id: Target conversation
            role: Message role (user/assistant/system)
            content: Message content
            priority: Message priority
            message_id: Optional database message ID
            metadata: Optional metadata
            
        Returns:
            True if added successfully
        """
        with self._lock:
            ctx = self._contexts.get(conversation_id)
            if not ctx:
                # Auto-create context
                ctx = self.create_context(conversation_id)
            
            # Estimate tokens
            tokens = TokenEstimator.estimate(content)
            
            # Create message
            msg = ContextMessage(
                role=role,
                content=content,
                tokens=tokens,
                priority=priority,
                message_id=message_id,
                metadata=metadata or {},
            )
            
            # Check if we need to make room
            while ctx.available_tokens() < tokens and len(ctx.messages) > 0:
                self._drop_lowest_priority(ctx)
            
            # Add message
            ctx.messages.append(msg)
            ctx.total_tokens += tokens
            
            # Check message limit
            while len(ctx.messages) > ctx.max_messages:
                self._drop_lowest_priority(ctx)
            
            self._stats['messages_added'] += 1
            
            # Invalidate cache
            self._invalidate_cache(conversation_id)
            
            # Check for auto-summarization
            if self._enable_auto_summarize:
                self._check_summarization_trigger(conversation_id)
            
            return True
    
    def _drop_lowest_priority(self, ctx: ContextWindow):
        """Drop the lowest priority message from context"""
        if not ctx.messages:
            return
        
        # Find lowest priority message (but never drop CRITICAL)
        lowest_idx = None
        lowest_priority = ContextPriority.CRITICAL
        
        for idx, msg in enumerate(ctx.messages):
            if msg.priority.value < lowest_priority.value:
                lowest_priority = msg.priority
                lowest_idx = idx
        
        if lowest_idx is not None:
            dropped = ctx.messages.pop(lowest_idx)
            ctx.total_tokens -= dropped.tokens
            self._stats['messages_dropped'] += 1
            logger.debug(f"Dropped message with priority {lowest_priority.name}")
    
    def get_messages_for_api(
        self,
        conversation_id: str,
        include_system: bool = True
    ) -> List[Dict[str, str]]:
        """
        Get messages formatted for API call.
        
        Args:
            conversation_id: Target conversation
            include_system: Include system prompt
            
        Returns:
            List of messages in API format
        """
        with self._lock:
            ctx = self._contexts.get(conversation_id)
            if not ctx:
                return []
            
            messages = []
            
            # Add system prompt
            if include_system and ctx.system_prompt:
                messages.append({
                    "role": "system",
                    "content": ctx.system_prompt
                })
            
            # Add messages
            for msg in ctx.messages:
                messages.append(msg.to_api_format())
            
            return messages
    
    def get_recent_messages(
        self,
        conversation_id: str,
        count: int = 20
    ) -> List[ContextMessage]:
        """Get most recent messages from context"""
        with self._lock:
            ctx = self._contexts.get(conversation_id)
            if not ctx:
                return []
            
            return ctx.messages[-count:]
    
    def truncate_to_tokens(
        self,
        conversation_id: str,
        max_tokens: int
    ) -> int:
        """
        Truncate context to fit within token limit.
        
        Args:
            conversation_id: Target conversation
            max_tokens: Maximum tokens allowed
            
        Returns:
            Number of messages dropped
        """
        with self._lock:
            ctx = self._contexts.get(conversation_id)
            if not ctx:
                return 0
            
            dropped = 0
            target_tokens = max_tokens - ctx.system_prompt_tokens - 512  # Reserve for response
            
            while ctx.total_tokens > target_tokens and len(ctx.messages) > 0:
                self._drop_lowest_priority(ctx)
                dropped += 1
            
            return dropped
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # SUMMARIZATION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def _check_summarization_trigger(self, conversation_id: str):
        """Check if summarization should be triggered"""
        ctx = self._contexts.get(conversation_id)
        if not ctx:
            return
        
        utilization = ctx.utilization_percent()
        
        if utilization >= self.SUMMARIZE_THRESHOLD_PERCENT:
            if len(ctx.messages) >= self.MIN_MESSAGES_TO_SUMMARIZE:
                self.summarize(conversation_id, SummarizationTrigger.TOKEN_LIMIT)
    
    def summarize(
        self,
        conversation_id: str,
        trigger: SummarizationTrigger = SummarizationTrigger.MANUAL,
        messages_to_summarize: int = None
    ) -> SummarizationResult:
        """
        Summarize older messages in context.
        
        Args:
            conversation_id: Target conversation
            trigger: What triggered summarization
            messages_to_summarize: Number of messages to summarize (default: half)
            
        Returns:
            SummarizationResult
        """
        with self._lock:
            ctx = self._contexts.get(conversation_id)
            if not ctx or len(ctx.messages) < self.MIN_MESSAGES_TO_SUMMARIZE:
                return SummarizationResult(success=False)
            
            # Determine how many messages to summarize
            if messages_to_summarize is None:
                messages_to_summarize = len(ctx.messages) // 2
            
            # Get messages to summarize (skip recent ones and critical)
            to_summarize = []
            keep_indices = set()
            
            for idx, msg in enumerate(ctx.messages):
                # Always keep recent messages and critical ones
                if idx >= len(ctx.messages) - 4 or msg.priority == ContextPriority.CRITICAL:
                    keep_indices.add(idx)
                elif len(to_summarize) < messages_to_summarize:
                    to_summarize.append(msg)
                    keep_indices.add(idx)  # Will be replaced with summary
            
            if not to_summarize:
                return SummarizationResult(success=False)
            
            tokens_before = sum(m.tokens for m in to_summarize)
            
            # Generate summary
            if self._summarize_callback:
                summary_text = self._summarize_callback(to_summarize)
            else:
                summary_text = self._generate_simple_summary(to_summarize)
            
            # Create summary message
            summary_tokens = TokenEstimator.estimate(summary_text)
            summary_msg = ContextMessage(
                role="system",
                content=f"[Context Summary: {summary_text}]",
                tokens=summary_tokens,
                priority=ContextPriority.HIGH,
                is_summarized=True,
                original_content="\n".join(m.content for m in to_summarize),
            )
            
            # Update context
            # Remove summarized messages and add summary
            new_messages = [m for idx, m in enumerate(ctx.messages) if idx not in keep_indices or idx >= len(ctx.messages) - 4]
            
            # Insert summary at the right position
            insert_pos = len(new_messages) - 4 if len(new_messages) > 4 else 0
            new_messages.insert(insert_pos, summary_msg)
            
            # Recalculate tokens
            ctx.messages = new_messages
            ctx.total_tokens = sum(m.tokens for m in ctx.messages)
            
            # Record result
            result = SummarizationResult(
                success=True,
                summary=summary_text,
                original_messages=len(to_summarize),
                summarized_messages=1,
                tokens_before=tokens_before,
                tokens_after=summary_tokens,
                compression_ratio=tokens_before / max(1, summary_tokens),
            )
            
            # Store in history
            if conversation_id not in self._summarization_history:
                self._summarization_history[conversation_id] = []
            self._summarization_history[conversation_id].append(result)
            
            self._stats['summarizations'] += 1
            
            # Invalidate cache
            self._invalidate_cache(conversation_id)
            
            logger.info(f"Summarized {result.original_messages} messages ({result.compression_ratio:.1f}x compression)")
            
            return result
    
    def _generate_simple_summary(self, messages: List[ContextMessage]) -> str:
        """Generate a simple summary without AI"""
        # Count message types
        user_msgs = [m for m in messages if m.role == "user"]
        assistant_msgs = [m for m in messages if m.role == "assistant"]
        
        # Extract key topics (simple keyword extraction)
        all_text = " ".join(m.content for m in messages)
        words = all_text.lower().split()
        
        # Filter common words
        stopwords = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been',
                     'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',
                     'would', 'could', 'should', 'may', 'might', 'must', 'shall',
                     'can', 'need', 'to', 'of', 'in', 'for', 'on', 'with', 'at',
                     'by', 'from', 'as', 'into', 'through', 'during', 'before',
                     'after', 'above', 'below', 'between', 'under', 'again',
                     'further', 'then', 'once', 'here', 'there', 'when', 'where',
                     'why', 'how', 'all', 'each', 'few', 'more', 'most', 'other',
                     'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same',
                     'so', 'than', 'too', 'very', 'just', 'and', 'but', 'if',
                     'or', 'because', 'until', 'while', 'this', 'that', 'these',
                     'those', 'i', 'you', 'he', 'she', 'it', 'we', 'they', 'what'}
        
        word_freq = {}
        for word in words:
            if word not in stopwords and len(word) > 3:
                word_freq[word] = word_freq.get(word, 0) + 1
        
        top_words = sorted(word_freq.keys(), key=lambda w: word_freq[w], reverse=True)[:5]
        
        # Build summary
        parts = []
        parts.append(f"{len(user_msgs)} user messages, {len(assistant_msgs)} responses")
        
        if top_words:
            parts.append(f"Topics: {', '.join(top_words)}")
        
        # Include first user message snippet
        if user_msgs:
            first_msg = user_msgs[0].content[:100]
            parts.append(f"Started with: \"{first_msg}...\"")
        
        return ". ".join(parts)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CONTEXT ADAPTATION
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def adapt_for_model(
        self,
        conversation_id: str,
        model: str
    ) -> List[Dict[str, str]]:
        """
        Adapt context for a specific model's context limit.
        
        Args:
            conversation_id: Target conversation
            model: Model identifier
            
        Returns:
            Messages formatted for the model
        """
        # Get model's context limit
        context_limit = self.MODEL_CONTEXT_LIMITS.get(model, self.MODEL_CONTEXT_LIMITS['default'])
        
        with self._lock:
            ctx = self._contexts.get(conversation_id)
            if not ctx:
                return []
            
            # Check if we need to truncate
            if ctx.total_tokens + ctx.system_prompt_tokens > context_limit - 512:
                # Create a temporary copy for truncation
                self.truncate_to_tokens(conversation_id, context_limit)
            
            return self.get_messages_for_api(conversation_id)
    
    def get_context_limit_for_model(self, model: str) -> int:
        """Get context limit for a model"""
        return self.MODEL_CONTEXT_LIMITS.get(model, self.MODEL_CONTEXT_LIMITS['default'])
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # CACHING
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def get_cached_context(
        self,
        conversation_id: str
    ) -> Optional[List[Dict[str, str]]]:
        """Get cached context if valid"""
        with self._cache_lock:
            snapshot = self._cache.get(conversation_id)
            
            if snapshot:
                # Verify checksum
                expected = snapshot.compute_checksum()
                if snapshot.checksum == expected:
                    self._stats['cache_hits'] += 1
                    return [msg for msg in snapshot.messages]
            
            self._stats['cache_misses'] += 1
            return None
    
    def _invalidate_cache(self, conversation_id: str):
        """Invalidate cache for a conversation"""
        with self._cache_lock:
            if conversation_id in self._cache:
                del self._cache[conversation_id]
    
    def snapshot_context(self, conversation_id: str) -> Optional[ContextSnapshot]:
        """Create a snapshot of current context"""
        with self._lock:
            ctx = self._contexts.get(conversation_id)
            if not ctx:
                return None
            
            snapshot = ContextSnapshot(
                conversation_id=conversation_id,
                messages=[m.to_api_format() for m in ctx.messages],
                total_tokens=ctx.total_tokens,
                created_at=time.time(),
            )
            snapshot.checksum = snapshot.compute_checksum()
            
            with self._cache_lock:
                self._cache[conversation_id] = snapshot
            
            return snapshot
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # MANAGEMENT
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    
    def clear_context(self, conversation_id: str):
        """Clear a context"""
        with self._lock:
            if conversation_id in self._contexts:
                del self._contexts[conversation_id]
            
            self._invalidate_cache(conversation_id)
    
    def get_stats(self) -> Dict[str, Any]:
        """Get manager statistics"""
        with self._lock:
            return {
                **self._stats,
                'active_contexts': len(self._contexts),
                'cache_size': len(self._cache),
            }
    
    def get_context_stats(self, conversation_id: str) -> Optional[Dict[str, Any]]:
        """Get statistics for a specific context"""
        ctx = self._contexts.get(conversation_id)
        if not ctx:
            return None
        
        return {
            'message_count': len(ctx.messages),
            'total_tokens': ctx.total_tokens,
            'max_tokens': ctx.max_tokens,
            'available_tokens': ctx.available_tokens(),
            'utilization_percent': ctx.utilization_percent(),
            'system_prompt_tokens': ctx.system_prompt_tokens,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GLOBAL INSTANCE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_manager: Optional[ContextManager] = None


def get_context_manager() -> ContextManager:
    """Get global ContextManager instance"""
    global _manager
    if _manager is None:
        _manager = ContextManager()
    return _manager


def initialize_context_manager(**kwargs) -> ContextManager:
    """Initialize global manager with custom settings"""
    global _manager
    _manager = ContextManager(**kwargs)
    return _manager


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SELF TEST
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def self_test() -> Dict[str, Any]:
    """Run self-test for ContextManager"""
    results = {
        'passed': [],
        'failed': [],
        'warnings': [],
    }
    
    manager = ContextManager(default_max_tokens=1000)
    
    # Test 1: Create context
    ctx = manager.create_context("test-conv", max_tokens=500)
    if ctx and ctx.max_tokens == 500:
        results['passed'].append('create_context')
    else:
        results['failed'].append('create_context')
    
    # Test 2: Set system prompt
    success = manager.set_system_prompt("test-conv", "You are a test assistant.")
    if success:
        ctx = manager.get_context("test-conv")
        if ctx and ctx.system_prompt == "You are a test assistant.":
            results['passed'].append('set_system_prompt')
        else:
            results['failed'].append('set_system_prompt')
    else:
        results['failed'].append('set_system_prompt')
    
    # Test 3: Add messages
    manager.add_message("test-conv", "user", "Hello!")
    manager.add_message("test-conv", "assistant", "Hi there! How can I help?")
    
    ctx = manager.get_context("test-conv")
    if ctx and len(ctx.messages) == 2:
        results['passed'].append('add_messages')
    else:
        results['failed'].append(f'add_messages: {len(ctx.messages) if ctx else 0} messages')
    
    # Test 4: Get messages for API
    api_messages = manager.get_messages_for_api("test-conv")
    if len(api_messages) == 3:  # system + 2 messages
        results['passed'].append('get_messages_for_api')
    else:
        results['failed'].append(f'get_messages_for_api: {len(api_messages)} messages')
    
    # Test 5: Token estimation
    tokens = TokenEstimator.estimate("Hello, this is a test message!")
    if tokens > 0:
        results['passed'].append('token_estimation')
    else:
        results['failed'].append('token_estimation')
    
    # Test 6: Context truncation
    # Add many messages to trigger truncation
    for i in range(20):
        manager.add_message("test-conv", "user", f"Message number {i} with some extra content to use tokens")
    
    ctx = manager.get_context("test-conv")
    if ctx and ctx.total_tokens <= ctx.max_tokens:
        results['passed'].append('auto_truncation')
    else:
        results['warnings'].append(f'auto_truncation: tokens={ctx.total_tokens if ctx else 0}')
    
    # Test 7: Context stats
    stats = manager.get_context_stats("test-conv")
    if stats and 'utilization_percent' in stats:
        results['passed'].append('context_stats')
    else:
        results['failed'].append('context_stats')
    
    # Test 8: Clear context
    manager.clear_context("test-conv")
    ctx = manager.get_context("test-conv")
    if ctx is None:
        results['passed'].append('clear_context')
    else:
        results['failed'].append('clear_context')
    
    results['stats'] = manager.get_stats()
    
    return results


if __name__ == "__main__":
    print("=" * 70)
    print("JARVIS Context Manager - Self Test")
    print("=" * 70)
    print(f"Device: Realme 2 Pro Lite (RMP2402)")
    print("-" * 70)
    
    test_results = self_test()
    
    print("\nâœ… Passed Tests:")
    for test in test_results['passed']:
        print(f"   âœ“ {test}")
    
    if test_results['failed']:
        print("\nâŒ Failed Tests:")
        for test in test_results['failed']:
            print(f"   âœ— {test}")
    
    if test_results['warnings']:
        print("\nâš ï¸  Warnings:")
        for warning in test_results['warnings']:
            print(f"   ! {warning}")
    
    print("\nğŸ“Š Statistics:")
    stats = test_results['stats']
    for key, value in stats.items():
        print(f"   {key}: {value}")
    
    print("\n" + "=" * 70)
